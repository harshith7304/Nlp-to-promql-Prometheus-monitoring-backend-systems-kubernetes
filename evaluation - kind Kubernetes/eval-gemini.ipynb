{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_TOKEN\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,  # Ensures deterministic results\n",
    "    max_tokens=512,  # Keeps responses concise but informative\n",
    "    timeout=20,  # Avoids long hangs\n",
    "    max_retries=3,  # Handles transient failures\n",
    "    verbose=True  # Enables debugging info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"test_queries.csv\")\n",
    "\n",
    "nl_queries = df[\"nl_query\"].tolist()\n",
    "expected_outputs = df[\"expected_output\"].tolist()\n",
    "rag_v1_outputs = df[\"rag_v1_output\"].tolist()\n",
    "rag_v2_outputs = df[\"rag_v2_output\"].tolist()\n",
    "rag_v3_outputs = df[\"rag_v3_output\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "promql_evaluation_template = \"\"\"\n",
    "You are an expert in PromQL and query evaluation. Your task is to evaluate the correctness of a model-generated query compared to the expected output based on a natural language query. Provide detailed feedback and assign a score (on a scale of 0 to 10) based on the following criteria:\n",
    "\n",
    "### Scoring Criteria:\n",
    "1. **Semantic Equivalence** (0.4 points):\n",
    "   - Is the model output semantically equivalent to the expected output? Evaluate how closely it matches in terms of functionality.\n",
    "\n",
    "2. **Correctness** (0.3 points):\n",
    "   - Are all key components of the query (e.g., aggregation functions, filters, time ranges) accurate and relevant to the natural language query?\n",
    "\n",
    "3. **Optimization** (0.2 points):\n",
    "   - Is the output efficient and aligned with best practices for PromQL queries?\n",
    "\n",
    "4. **Overall Clarity** (0.1 point):\n",
    "   - Is the query clean and easy to understand?\n",
    "\n",
    "### Inputs:\n",
    "- **NL Query**: {nl_query}  \n",
    "- **Expected Output**: {expected_output}  \n",
    "- **Model Output**: {rag_output}  \n",
    "\n",
    "### Example Response Format:\n",
    "1. **Semantic Equivalence**:\n",
    "   - Score: X/0.4\n",
    "   - Explanation: [Explanation of the alignment]\n",
    "\n",
    "2. **Correctness**:\n",
    "   - Score: X/0.3\n",
    "   - Explanation: [Analysis of key components]\n",
    "\n",
    "3. **Optimization**:\n",
    "   - Score: X/0.2\n",
    "   - Explanation: [Improvement suggestions]\n",
    "\n",
    "4. **Overall Clarity**:\n",
    "   - Score: X/0.1\n",
    "   - Explanation: [Comment on query clarity]\n",
    "\n",
    "5. **Total Score**:\n",
    "   - X (in decimal format, e.g., 0.7)\n",
    "\n",
    "Evaluate and provide the scores with explanations.\n",
    "\"\"\"\n",
    "\n",
    "promql_evaluation_prompt = PromptTemplate.from_template(promql_evaluation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "evaluation_chain = (\n",
    "    {\n",
    "        \"nl_query\": RunnablePassthrough(),\n",
    "        \"expected_output\": RunnablePassthrough(),\n",
    "        \"rag_output\": RunnablePassthrough(),\n",
    "    }\n",
    "    | promql_evaluation_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "score_extraction_template = \"\"\"\n",
    "From the input provided, extract and return only the total score as a decimal number. Do not include any additional text, symbols, or formatting, just the score in float form.\n",
    "\n",
    "input: {query}\n",
    "\"\"\"\n",
    "\n",
    "score_extraction_prompt = PromptTemplate.from_template(score_extraction_template)\n",
    "\n",
    "score_extraction_chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | score_extraction_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1, sleeping for 60 seconds...\n",
      "Completed batch 2, sleeping for 60 seconds...\n",
      "Completed batch 3, sleeping for 60 seconds...\n",
      "Completed batch 4, sleeping for 60 seconds...\n",
      "Completed batch 5, sleeping for 60 seconds...\n",
      "Error processing query 51: could not convert string to float: '0.  1'\n",
      "Completed batch 6, sleeping for 60 seconds...\n",
      "Error processing query 63: could not convert string to float: '1.  0'\n",
      "Completed batch 7, sleeping for 60 seconds...\n",
      "Completed batch 8, sleeping for 60 seconds...\n",
      "Completed batch 9, sleeping for 60 seconds...\n",
      "Error processing query 92: could not convert string to float: '0.  0'\n",
      "Error processing query 93: could not convert string to float: '0.  0'\n",
      "Completed batch 10, sleeping for 60 seconds...\n",
      "Error processing query 102: could not convert string to float: '0.  0'\n",
      "Completed batch 11, sleeping for 60 seconds...\n",
      "Completed batch 12, sleeping for 60 seconds...\n",
      "Error processing query 122: could not convert string to float: '0.  0'\n",
      "Completed batch 13, sleeping for 60 seconds...\n",
      "Completed batch 14, sleeping for 60 seconds...\n",
      "Completed batch 15, sleeping for 60 seconds...\n",
      "Completed batch 16, sleeping for 60 seconds...\n",
      "Completed batch 17, sleeping for 60 seconds...\n",
      "Completed batch 18, sleeping for 60 seconds...\n",
      "Error processing query 181: could not convert string to float: '0.  0'\n",
      "Completed batch 19, sleeping for 60 seconds...\n",
      "[0.4, 0.5, 0.9, 0.2, 0.78, 0.4, 0.5, 0.4, 0.85, 0.9, 0.7, 0.5, 0.2, 0.8, 0.6, 0.6, 0.4, 0.8, 0.85, 0.7, 0.5, 0.4, 0.7, 0.5, 0.5, 0.4, 0.5, 0.5, 0.85, 0.4, 0.5, 0.7, 0.6, 0.3, 0.4, 0.5, 0.6, 0.4, 0.6, 0.1, 0.2, 0.78, 0.7, 0.4, 0.85, 0.3, 0.6, 0.8, 0.7, 0.2, None, 0.4, 0.45, 0.8, 0.7, 0.5, 0.8, 0.7, 0.7, 0.3, 0.4, 0.85, None, 0.6, 0.5, 0.3, 0.7, 0.6, 0.4, 0.2, 0.4, 0.6, 0.5, 0.5, 0.4, 0.5, 0.4, 0.5, 0.4, 0.4, 0.2, 0.2, 0.6, 0.3, 0.6, 0.7, 0.4, 0.1, 0.2, 0.4, 0.7, None, None, 0.4, 0.2, 0.2, 0.4, 0.2, 0.5, 0.4, 0.5, None, 0.85, 0.5, 0.6, 0.4, 0.4, 0.7, 0.2, 0.4, 0.4, 0.4, 0.8, 0.5, 0.65, 0.4, 0.4, 0.4, 0.3, 0.4, 0.2, None, 0.5, 0.5, 0.4, 0.4, 0.7, 0.5, 0.4, 0.2, 0.1, 0.6, 0.4, 0.5, 0.7, 0.4, 0.0, 0.2, 0.4, 0.7, 0.1, 0.5, 0.5, 0.4, 0.4, 0.4, 0.2, 0.5, 0.5, 0.5, 0.2, 0.85, 0.5, 0.6, 0.4, 0.4, 0.7, 0.1, 0.4, 0.0, 0.4, 0.8, 0.5, 0.7, 0.4, 0.4, 0.4, 0.3, 0.4, 0.4, 0.2, 0.4, 0.4, 0.3, 0.7, 0.5, 0.5, 0.3, 0.4, 0.1, None, 0.45, 0.7, 0.5, 0.5, 0.1]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "rag_v1_scores = []\n",
    "batch_size = 10  # Reduce batch size to avoid API pressure\n",
    "delay_per_request = 5  # Add a small delay per request to avoid spikes\n",
    "\n",
    "for i in range(0, len(nl_queries), batch_size):\n",
    "    batch_queries = nl_queries[i : i + batch_size]\n",
    "    batch_expected_outputs = expected_outputs[i : i + batch_size]\n",
    "    batch_rag_outputs = rag_v1_outputs[i : i + batch_size]\n",
    "\n",
    "    for j in range(len(batch_queries)):\n",
    "        nl_query = batch_queries[j]\n",
    "        expected_output = batch_expected_outputs[j]\n",
    "        rag_output = batch_rag_outputs[j]\n",
    "\n",
    "        inputs = {\n",
    "            \"nl_query\": nl_query,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"model_output\": rag_output,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = evaluation_chain.invoke(inputs)\n",
    "            score = score_extraction_chain.invoke(result)\n",
    "            rag_v1_scores.append(float(score))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {i + j + 1}: {e}\")\n",
    "            rag_v1_scores.append(None)\n",
    "\n",
    "        time.sleep(delay_per_request)  # Short delay between requests to avoid 429 errors\n",
    "\n",
    "    print(f\"Completed batch {i // batch_size + 1}, sleeping for 60 seconds...\")\n",
    "    time.sleep(60)  # Ensure we stay under the 15 RPM limit\n",
    "\n",
    "print(rag_v1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Average Score for rag_v1_output: 0.4724\n"
     ]
    }
   ],
   "source": [
    "valid_scores = [score for score in rag_v1_scores if score is not None]  # Remove None values\n",
    "average_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0  # Avoid division by zero\n",
    "\n",
    "print(f\"ðŸ“Š Average Score for rag_v1_output: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1, sleeping for 60 seconds...\n",
      "Error processing query 12: could not convert string to float: '1.  0'\n",
      "Completed batch 2, sleeping for 60 seconds...\n",
      "Completed batch 3, sleeping for 60 seconds...\n",
      "Completed batch 4, sleeping for 60 seconds...\n",
      "Completed batch 5, sleeping for 60 seconds...\n",
      "Completed batch 6, sleeping for 60 seconds...\n",
      "Error processing query 63: could not convert string to float: '1.  0'\n",
      "Completed batch 7, sleeping for 60 seconds...\n",
      "Completed batch 8, sleeping for 60 seconds...\n",
      "Error processing query 81: could not convert string to float: '0.  3'\n",
      "Completed batch 9, sleeping for 60 seconds...\n",
      "Completed batch 10, sleeping for 60 seconds...\n",
      "Completed batch 11, sleeping for 60 seconds...\n",
      "Error processing query 112: could not convert string to float: '1.  0'\n",
      "Completed batch 12, sleeping for 60 seconds...\n",
      "Completed batch 13, sleeping for 60 seconds...\n",
      "Completed batch 14, sleeping for 60 seconds...\n",
      "Error processing query 142: could not convert string to float: '0.  0'\n",
      "Completed batch 15, sleeping for 60 seconds...\n",
      "Completed batch 16, sleeping for 60 seconds...\n",
      "Completed batch 17, sleeping for 60 seconds...\n",
      "Completed batch 18, sleeping for 60 seconds...\n",
      "Completed batch 19, sleeping for 60 seconds...\n",
      "[0.4, 0.5, 0.8, 0.6, 0.8, 0.2, 0.5, 0.3, 0.4, 0.9, 0.6, None, 0.2, 0.8, 0.5, 0.6, 0.4, 0.4, 0.85, 0.7, 0.4, 0.4, 0.5, 0.4, 0.4, 0.5, 0.4, 0.5, 0.85, 0.4, 0.7, 0.6, 0.7, 0.2, 0.4, 0.4, 0.6, 0.5, 0.5, 0.1, 0.6, 0.4, 0.7, 0.4, 0.65, 0.2, 0.5, 0.4, 0.7, 0.4, 0.6, 0.7, 0.5, 0.8, 0.8, 0.5, 0.8, 0.7, 0.8, 0.7, 0.5, 0.85, None, 0.7, 0.6, 0.8, 0.7, 0.5, 0.7, 0.4, 0.75, 0.3, 0.5, 0.8, 0.4, 0.5, 0.4, 0.7, 0.4, 0.4, None, 0.0, 0.6, 0.5, 0.5, 0.8, 0.4, 0.4, 0.7, 0.3, 0.3, 0.2, 0.2, 0.3, 0.85, 0.4, 0.1, 0.2, 0.4, 0.4, 0.8, 0.0, 0.4, 0.4, 0.4, 0.5, 0.65, 0.4, 0.0, 0.4, 0.4, None, 0.5, 0.5, 0.3, 0.4, 0.5, 0.4, 0.2, 0.4, 0.4, 0.4, 0.85, 0.4, 0.2, 0.4, 0.7, 0.8, 0.4, 0.4, 0.2, 0.65, 0.0, 0.6, 0.5, 0.65, 0.8, 0.4, 0.3, 0.4, 0.0, None, 0.6, 0.8, 0.4, 0.5, 0.4, 0.4, 0.4, 0.78, 0.2, 0.5, 0.4, 0.5, 0.4, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.6, 0.4, 0.4, 0.4, 0.2, 0.4, 0.4, 0.4, 0.6, 0.4, 0.65, 0.4, 0.4, 0.4, 0.4, 0.1, 0.5, 0.5, 0.4, 0.3, 0.4, 0.4, 0.5, 0.85, 0.2]\n"
     ]
    }
   ],
   "source": [
    "rag_v2_scores = []\n",
    "batch_size = 10  # Reduce batch size to avoid API pressure\n",
    "delay_per_request = 5  # Add a small delay per request to avoid spikes\n",
    "\n",
    "for i in range(0, len(nl_queries), batch_size):\n",
    "    batch_queries = nl_queries[i : i + batch_size]\n",
    "    batch_expected_outputs = expected_outputs[i : i + batch_size]\n",
    "    batch_rag_outputs = rag_v2_outputs[i : i + batch_size]\n",
    "\n",
    "    for j in range(len(batch_queries)):\n",
    "        nl_query = batch_queries[j]\n",
    "        expected_output = batch_expected_outputs[j]\n",
    "        rag_output = batch_rag_outputs[j]\n",
    "\n",
    "        inputs = {\n",
    "            \"nl_query\": nl_query,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"model_output\": rag_output,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = evaluation_chain.invoke(inputs)\n",
    "            score = score_extraction_chain.invoke(result)\n",
    "            rag_v2_scores.append(float(score))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {i + j + 1}: {e}\")\n",
    "            rag_v2_scores.append(None)\n",
    "\n",
    "        time.sleep(delay_per_request)  # Short delay between requests to avoid 429 errors\n",
    "\n",
    "    print(f\"Completed batch {i // batch_size + 1}, sleeping for 60 seconds...\")\n",
    "    time.sleep(60)  # Ensure we stay under the 15 RPM limit\n",
    "\n",
    "print(rag_v2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Average Score for rag_v2_output: 0.4772\n"
     ]
    }
   ],
   "source": [
    "valid_scores = [score for score in rag_v2_scores if score is not None]  # Remove None values\n",
    "average_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0  # Avoid division by zero\n",
    "\n",
    "print(f\"ðŸ“Š Average Score for rag_v2_output: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1, sleeping for 60 seconds...\n",
      "Completed batch 2, sleeping for 60 seconds...\n",
      "Completed batch 3, sleeping for 60 seconds...\n",
      "Completed batch 4, sleeping for 60 seconds...\n",
      "Completed batch 5, sleeping for 60 seconds...\n",
      "Completed batch 6, sleeping for 60 seconds...\n",
      "Error processing query 63: could not convert string to float: '1.  0'\n",
      "Completed batch 7, sleeping for 60 seconds...\n",
      "Completed batch 8, sleeping for 60 seconds...\n",
      "Error processing query 89: could not convert string to float: '0.  0'\n",
      "Completed batch 9, sleeping for 60 seconds...\n",
      "Completed batch 10, sleeping for 60 seconds...\n",
      "Completed batch 11, sleeping for 60 seconds...\n",
      "Completed batch 12, sleeping for 60 seconds...\n",
      "Completed batch 13, sleeping for 60 seconds...\n",
      "Completed batch 14, sleeping for 60 seconds...\n",
      "Completed batch 15, sleeping for 60 seconds...\n",
      "Completed batch 16, sleeping for 60 seconds...\n",
      "Completed batch 17, sleeping for 60 seconds...\n",
      "Completed batch 18, sleeping for 60 seconds...\n",
      "Error processing query 181: could not convert string to float: '0.  0'\n",
      "Completed batch 19, sleeping for 60 seconds...\n",
      "[0.4, 0.5, 0.6, 0.3, 0.4, 0.2, 0.4, 0.2, 0.85, 0.7, 0.5, 0.5, 0.1, 0.8, 0.5, 0.6, 0.8, 0.8, 0.85, 0.7, 0.5, 0.4, 0.4, 0.5, 0.5, 0.5, 0.6, 0.5, 0.85, 0.4, 0.6, 0.7, 0.6, 0.1, 0.5, 0.5, 0.4, 0.4, 0.7, 0.2, 0.1, 0.8, 0.85, 0.5, 0.8, 0.4, 0.5, 0.78, 0.8, 0.4, 0.6, 0.5, 0.4, 0.7, 0.5, 0.5, 0.85, 0.7, 0.8, 0.65, 0.3, 0.85, None, 0.7, 0.5, 0.2, 0.7, 0.5, 0.4, 0.4, 0.4, 0.2, 0.4, 0.8, 0.4, 0.5, 0.6, 0.6, 0.4, 0.4, 0.4, 0.0, 0.5, 0.4, 0.6, 0.7, 0.7, 0.4, None, 0.4, 0.4, 0.0, 0.5, 0.4, 0.45, 0.1, 0.1, 0.4, 0.5, 0.4, 0.4, 0.4, 0.85, 0.4, 0.4, 0.4, 0.4, 0.6, 0.2, 0.4, 0.4, 0.1, 0.6, 0.5, 0.6, 0.5, 0.2, 0.4, 0.4, 0.4, 0.5, 0.1, 0.85, 0.4, 0.5, 0.6, 0.6, 0.4, 0.4, 0.4, 0.0, 0.5, 0.4, 0.6, 0.7, 0.7, 0.2, 0.0, 0.4, 0.4, 0.0, 0.5, 0.4, 0.35, 0.1, 0.1, 0.4, 0.5, 0.4, 0.4, 0.4, 0.85, 0.4, 0.4, 0.4, 0.4, 0.6, 0.2, 0.4, 0.4, 0.1, 0.6, 0.5, 0.6, 0.5, 0.2, 0.4, 0.4, 0.4, 0.5, 0.1, 0.7, 0.2, 0.65, 0.2, 0.5, 0.4, 0.3, 0.4, 0.3, None, 0.4, 0.45, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "rag_v3_scores = []\n",
    "batch_size = 10  # Reduce batch size to avoid API pressure\n",
    "delay_per_request = 5  # Add a small delay per request to avoid spikes\n",
    "\n",
    "for i in range(0, len(nl_queries), batch_size):\n",
    "    batch_queries = nl_queries[i : i + batch_size]\n",
    "    batch_expected_outputs = expected_outputs[i : i + batch_size]\n",
    "    batch_rag_outputs = rag_v3_outputs[i : i + batch_size]\n",
    "\n",
    "    for j in range(len(batch_queries)):\n",
    "        nl_query = batch_queries[j]\n",
    "        expected_output = batch_expected_outputs[j]\n",
    "        rag_output = batch_rag_outputs[j]\n",
    "\n",
    "        inputs = {\n",
    "            \"nl_query\": nl_query,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"model_output\": rag_output,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = evaluation_chain.invoke(inputs)\n",
    "            score = score_extraction_chain.invoke(result)\n",
    "            rag_v3_scores.append(float(score))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {i + j + 1}: {e}\")\n",
    "            rag_v3_scores.append(None)\n",
    "\n",
    "        time.sleep(delay_per_request)  # Short delay between requests to avoid 429 errors\n",
    "\n",
    "    print(f\"Completed batch {i // batch_size + 1}, sleeping for 60 seconds...\")\n",
    "    time.sleep(60)  # Ensure we stay under the 15 RPM limit\n",
    "\n",
    "print(rag_v3_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Average Score for rag_v2_output: 0.4611\n"
     ]
    }
   ],
   "source": [
    "valid_scores = [score for score in rag_v3_scores if score is not None]  # Remove None values\n",
    "average_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0  # Avoid division by zero\n",
    "\n",
    "print(f\"ðŸ“Š Average Score for rag_v2_output: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RAG Version  Average Score\n",
      "0      rag_v1       0.472402\n",
      "1      rag_v2       0.477238\n",
      "2      rag_v3       0.461093\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rag_v1_valid_scores = [score for score in rag_v1_scores if score is not None]\n",
    "rag_v2_valid_scores = [score for score in rag_v2_scores if score is not None]\n",
    "rag_v3_valid_scores = [score for score in rag_v3_scores if score is not None]\n",
    "\n",
    "\n",
    "# Calculate the average score for each RAG version\n",
    "rag_v1_avg = sum(rag_v1_valid_scores) / len(rag_v1_valid_scores)\n",
    "rag_v2_avg = sum(rag_v2_valid_scores) / len(rag_v2_valid_scores)\n",
    "rag_v3_avg = sum(rag_v3_valid_scores) / len(rag_v3_valid_scores)\n",
    "\n",
    "# Create a DataFrame to display the averages as a table\n",
    "data = {\n",
    "    'RAG Version': ['rag_v1', 'rag_v2', 'rag_v3'],\n",
    "    'Average Score': [rag_v1_avg, rag_v2_avg, rag_v3_avg]\n",
    "}\n",
    "\n",
    "# Create the DataFrame and display it\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
